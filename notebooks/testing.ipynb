{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worker Safety Detection System - Testing Notebook\n",
    "\n",
    "This notebook provides interactive examples for testing the worker safety detection system.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Configuration\n",
    "2. Load YOLOv8 Model\n",
    "3. Test on Sample Images\n",
    "4. Test Telegram Alerts\n",
    "5. Process Sample Video\n",
    "6. Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# For Telegram testing\n",
    "import asyncio\n",
    "from alert import test_telegram_connection, send_violation_alert\n",
    "from utils import draw_boxes, save_violation_screenshot\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = '../config/config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"Model path: {config['detection']['model_path']}\")\n",
    "print(f\"Confidence threshold: {config['detection']['confidence_threshold']}\")\n",
    "print(f\"Telegram alerts enabled: {config['telegram']['enable_alerts']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8 model\n",
    "model_path = f\"../{config['detection']['model_path']}\"\n",
    "\n",
    "print(f\"Loading model from {model_path}...\")\n",
    "model = YOLO(model_path)\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "\n",
    "# Display model info\n",
    "print(f\"\\nModel classes: {model.names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test on Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display images in notebook\n",
    "def show_image(img, title=\"Image\", figsize=(12, 8)):\n",
    "    \"\"\"Display image in notebook\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Helper function for detection\n",
    "def detect_and_visualize(image_path, model, config):\n",
    "    \"\"\"Run detection and visualize results\"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"‚ùå Could not read image: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    \n",
    "    # Run detection\n",
    "    results = model(img, conf=config['detection']['confidence_threshold'])\n",
    "    \n",
    "    # Display results\n",
    "    result = results[0]\n",
    "    print(f\"\\nDetections: {len(result.boxes)} objects found\")\n",
    "    \n",
    "    # Print detected classes\n",
    "    for box in result.boxes:\n",
    "        class_id = int(box.cls[0])\n",
    "        class_name = result.names[class_id]\n",
    "        confidence = float(box.conf[0])\n",
    "        print(f\"  - {class_name}: {confidence:.2f}\")\n",
    "    \n",
    "    # Visualize\n",
    "    annotated = result.plot()\n",
    "    show_image(annotated, f\"Detections: {image_path}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test on an image\n",
    "# Replace with your own image path\n",
    "test_image = \"../data/images/test_image.jpg\"\n",
    "\n",
    "# Check if image exists\n",
    "if os.path.exists(test_image):\n",
    "    results = detect_and_visualize(test_image, model, config)\n",
    "else:\n",
    "    print(f\"‚ùå Test image not found: {test_image}\")\n",
    "    print(\"Place a test image in data/images/ folder and update the path above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Telegram Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Telegram connection\n",
    "bot_token = config['telegram']['bot_token']\n",
    "chat_id = config['telegram']['chat_id']\n",
    "\n",
    "if bot_token != \"YOUR_BOT_TOKEN_HERE\" and chat_id != \"YOUR_CHAT_ID_HERE\":\n",
    "    print(\"Testing Telegram connection...\")\n",
    "    await test_telegram_connection(bot_token, chat_id)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please configure Telegram bot token and chat ID in config/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sending a violation alert with sample data\n",
    "if bot_token != \"YOUR_BOT_TOKEN_HERE\" and chat_id != \"YOUR_CHAT_ID_HERE\":\n",
    "    # Create sample violation data\n",
    "    sample_violations = [\n",
    "        {\n",
    "            'class': 'no-helmet',\n",
    "            'confidence': 0.89,\n",
    "            'bbox': [100, 150, 300, 400]\n",
    "        },\n",
    "        {\n",
    "            'class': 'no-safety-vest',\n",
    "            'confidence': 0.76,\n",
    "            'bbox': [120, 200, 280, 450]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # You would need an actual image file for this to work\n",
    "    # sample_image_path = \"path/to/sample/image.jpg\"\n",
    "    # await send_violation_alert(bot_token, chat_id, sample_image_path, sample_violations)\n",
    "    \n",
    "    print(\"To test alerts, uncomment the code above and provide a valid image path.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Please configure Telegram credentials first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process Sample Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a video file\n",
    "from detect import SafetyDetector\n",
    "\n",
    "video_path = \"../data/videos/test.mp4\"\n",
    "\n",
    "if os.path.exists(video_path):\n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    \n",
    "    # Initialize detector\n",
    "    detector = SafetyDetector('../config/config.yaml')\n",
    "    \n",
    "    # Process video\n",
    "    detector.process_video(video_path)\n",
    "    \n",
    "    print(\"\\n‚úÖ Video processing complete!\")\n",
    "    print(\"Check output/videos/ for the annotated video.\")\n",
    "    print(\"Check output/violations/ for violation screenshots.\")\n",
    "else:\n",
    "    print(f\"‚ùå Video not found: {video_path}\")\n",
    "    print(\"Place a test video in data/videos/ folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Detection Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some frames from the processed video\n",
    "def visualize_video_frames(video_path, num_frames=5):\n",
    "    \"\"\"Extract and visualize random frames from video\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Could not open video: {video_path}\")\n",
    "        return\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total frames in video: {total_frames}\")\n",
    "    \n",
    "    # Select random frames\n",
    "    frame_indices = np.linspace(0, total_frames-1, num_frames, dtype=int)\n",
    "    \n",
    "    for idx in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            # Run detection\n",
    "            results = model(frame, conf=config['detection']['confidence_threshold'])\n",
    "            annotated = results[0].plot()\n",
    "            \n",
    "            show_image(annotated, f\"Frame {idx}/{total_frames}\")\n",
    "    \n",
    "    cap.release()\n",
    "    print(\"‚úÖ Visualization complete!\")\n",
    "\n",
    "# Uncomment to visualize frames from your video\n",
    "# visualize_video_frames(\"../data/videos/test.mp4\", num_frames=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. View Saved Violation Screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List and display violation screenshots\n",
    "violations_dir = \"../output/violations/\"\n",
    "\n",
    "if os.path.exists(violations_dir):\n",
    "    violation_images = list(Path(violations_dir).glob(\"*.jpg\"))\n",
    "    \n",
    "    print(f\"Found {len(violation_images)} violation screenshots\")\n",
    "    \n",
    "    # Display first few violations\n",
    "    for img_path in violation_images[:5]:  # Show first 5\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is not None:\n",
    "            show_image(img, f\"Violation: {img_path.name}\")\n",
    "else:\n",
    "    print(\"No violations found yet. Run video processing first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Statistics and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze violation patterns\n",
    "violations_dir = Path(\"../output/violations/\")\n",
    "\n",
    "if violations_dir.exists():\n",
    "    violation_files = list(violations_dir.glob(\"*.jpg\"))\n",
    "    \n",
    "    print(f\"üìä Violation Statistics\")\n",
    "    print(f\"=\"*50)\n",
    "    print(f\"Total violation screenshots: {len(violation_files)}\")\n",
    "    \n",
    "    if violation_files:\n",
    "        # Get file timestamps\n",
    "        timestamps = [f.stem.split('_')[1:] for f in violation_files]\n",
    "        print(f\"First violation: {violation_files[0].name}\")\n",
    "        print(f\"Latest violation: {violation_files[-1].name}\")\n",
    "else:\n",
    "    print(\"No violations directory found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Train Custom Model**: For better accuracy, train YOLOv8 on a PPE-specific dataset\n",
    "2. **Live Camera**: Integrate with RTSP streams for real-time monitoring\n",
    "3. **Dashboard**: Create a web dashboard for monitoring multiple cameras\n",
    "4. **Database**: Store violation records in a database for analytics\n",
    "5. **Multi-camera**: Extend to monitor multiple cameras simultaneously\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Testing! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
